# PROFUNGIS

Processing of Fungal ITS Sequences
This pipeline has been created to download SRA studies of fungal ITS markers that will be used to construct a unique set of Z(ero radiance) OTUS to analyse fungal diversity.

## Installing PROFUNGIS

Install before usage:
  - Snakemake
  - BLAST+
  - usearch v11
    - rename the executable file 'usearch11' and place in /deps/ folder

To check if all dependencies are placed correctly, execute the checkDependencies.sh script found in this repo.

## The PROFUNGIS workflow
PROFUNGIS is divided into three main steps: 
- preprocessing
- denoising
- postprocessing

### overview of workflow steps

- **preprocessing**
  
In the preprocessing step, the reads corresponding to the provided SRA run id(s) will be downloaded into the ./sample/ directory. Next, the presence of the provided primers in the primer datafile is checked. 
If one or both of the primers are missing, the user is asked to provide the sequence and the part of ITS it amplifies.
Based on the collection of the user-provided parameters, a configuration file is created (config.yml). This file is required by the denoising part of the pipeline.

- **Denoising**
  
The denoising pipeline follows a mostly basic runthrough of ZOTU
construction. First, the provided primers are cut from both ends of the
reads. If the reads are generated by a paired-end Illumina library, the 
**DecideMerger** script is called. This step is skipped in pyrosequencing
platforms. The DecideMerger script decides if the paired-end reads
should be merged, or that only the forward reads should be used. If
the library has been sequenced using a pyrosequencing platform
(iontorrent or 454), and the amplicon is a partial ITS sequence
(ITS1 or ITS2), the reads are truncated to 250 bp, to ensure
same treatment. Whether or not the amplicon is a partial ITS
sequences is determined based on the user input primer names.
For every primer, its location relative to ITS is added.

Next, the average Estimated Error (EE) is used using the cor-
responding USEARCH function. If the user has provided the argument to use a fixed EE, this is used to filter. If not, mean EE
is used to filter the reads. The next step is dereplication of the
reads. After that, singletons are removed and the denoising step
is initiated. This step used the UNOISE3 algorithm to select
biological sequences without clustering based on a fixed identity
percentage. For more information on this step, see section 6.3.
After this step, the reads are remapped to the ZOTUS and a
ZOTU table containing the number of mapped reads is created.

- **postprocessing**
  
The postprocessing step of the pipeline involves an abundance
filter and a contamination filter. First, the pipeline will use the
ZOTU table to remove all sequences that have less than 0.1% of
the reads in that sample. Next, the contamination filter will use
BLAST to align the ZOTUS to the UNITE database. This is
done to 1) remove putative ZOTUS that are not somewhat sim-
ilar to known ITS sequences and 2) to remove putative ZOTUS
that are not asociated with a fungus. If a ZOTU has a hit with
more than 70% identity and the hit is a fungus, it is retained. If
not, it is removed.

## How to run PROFUNGIS

1. check dependencies

```shell
bash checkDependencies . sh
```
Continue if there are no errors. If everything is in place, you can start using PROFUNGIS pipeline. 

PROFUNGIS is dependent on several other tools. Please check the ./deps/folder to view the list. 

The tools that are provided are:

1. cutadapt (used in cutting primers)
2. faSomeRecords (used to select specific fasta sequences)
3. flash (used to merge paired-end reads)
4. primer.data (datafile containing primers)
5. sratoolkit (used to download SRA entries)
6. Trimmomatic (used to decide whether or not to merge)
7. UNITE (used to filter for contamination)
8. vsearch (used to dereplicate)

The tools that need to be installed. See Dockerfile and documentation as this can be done for you.

1. Python 3
2. Snakemake
3. BLAST+
4. usearch 11 (used for denoising)

*please note that USEARCH has a personal license. The personal license was removed in this public repository. In order to use the pipeline, you need to download the executable, rename it to "usearch11" and place it in the ./deps/ directory. 




```shell
bash checkDependencies . sh
```
Continue if there are no errors. If everything is in place, you can start using PROFUNGIS pipeline. 


Directory contains dependencies for PROFUNGIS
-cutadapt
-flash
-Trimmomatic
-faSomeRecords
-fasterq-dump
-vsearch

2. Run PROFUNGIS pipeline. In order to start, please launch startPROFUNGIS.py script. Please make sure you provide the correct arguments.

## PARAMETERS FOR PROFUNGIS

**List of mandatory parameters**

the mandatory arguments are:

| Name | acronym used for pipeline | expected input | definition |
| ---- | ---- | ----- | ----- |
| -forward | -f | primer name [String] | label of forward primer to refer to |
| -reverse | -r | primer name [String] | label of reverse primer to refer to |
| -platform | -p | platform name [illumina|454|iontorrent] | HTS plaform used for generating the read sequence file |
| -SRA | -s | one SRA id [String] | SRA sequence read ID (aka SRR) |
| -multirun | -m | file containg SRA ids | a list of SRRs provided in a .txt file |

**List of Optional parameters**

| Name | acronym used for pipeline | expected input | definition |
| ---- | ---- | ----- | ----- |
| -maxEE | -E | maximal estimated error [float] | expected error |
| -minOverlap | -o | minimal overlap in read merging [int] | number of basepairs for the minimal overlap |
| -minLen | -L | minimal length filter [int] | minimal length in basepairs for filter |
| -outdir | -O | output directory [String] | provide the path of the output directory to use for saving files |
| -local | -l | none [Flag] |  |

when the optional parameters are not provided, here are the values that the pipeline uses:
- maxEE: mean EE (1.0)
- minOverlap: 60 bp
- minLen: 100 bp
- outdir: current date and time (values used to generate the dir path, ISO date)
- local: False

These values are experimentally selected, either during development or by previous studies, thus it is recommended to provide the mandatory only, and stick to the optional values.
The local flag can be added when the reads are already downloaded. In order for the pipleine to use these reads, they need to be placed in the directory "./samples/[sample_name]/[sample_name].fastq" or both paired end files in the case of illumina platform generated.


**Running the pipeline** 

In order to run the pipeline, the mandatory arguments are required. This is for running via commandline. See below how to run the scripts in a docker environment. 
The list follows the order of arguments to pass to PROFUNGIS. 


Here we provide an example of running startPROFUNGIS.py with SRA read ID : SRR2002283. This ID is a public SRR obtained from NCBI SRA. Please note that to run startPROFUNGIS.py, you do not need to download the raw sequence files from SRA, this pipeline will do it for you by providing the reference ID.

```shell
python3 startPROFUNGIS . py --forward ExampleFwd -- reverse ExampleRev --platform illumina --SRA SRR2002283
```
The pipeline will read the primer names provided for the forward and reverse primers. These sequences are provided in the primer dataset (primers.py). If the script does not find them, the primers will be generated and saved for you. This is the case if you run for the first time this script. This means that ExamplePwd and ExampleRev are not in the primer file, thus the script will request for you to add them.
For running the first time, you can use and add the following primers:

```shell
CTTGGTCATTTAGAGGAAGTA 
```
for the forward primer. You will need to provide a primer label for this sequence, so you can refer to when running the scripts. In this case we can use the example label: ExampleFwd. This primer belongs to the ITS1 barcode is used.

```shell
GCTGCGTTCTTCATCGATG 
```
for the reverse primer, labelled ExampleRev. This primer is used for ITS1 barcode of ITS.

These primers will be added to the datafile and you can refer to them with *ExampleFwd* and *ExampleRev*.
You can always check the [primer.data](https://github.com/naturalis/mycodiversity/blob/master/PROFUNGIS/deps/primer.data) file containing the list of primers and if the primers you are considering are listerd already. 

### PROFUNGIS docker steps - helping to run PROFUNGIS on your own machine

## Pre-requirements for running the a startPROFUNGIS container

1. install Docker: [Docker installation](https://docs.docker.com/get-docker/). This main page contains instructions for *Windows*, *OS mac* and *Linux*.
2. have a GitHub account.

## Run docker steps

1. Clone this repository. For instructions how to clone repositories you can find here [clone](https://docs.github.com/en/repositories/creating-and-managing-repositories/cloning-a-repository)

2. Start Docker. Docker application also provides Docker Desktop, which is a handy interface to create images and install the container. Below i give the commands for running on the terminal. I run the docker in the same path I cloned the repository, else make sure you know the PATH of where you cloned the repository. The *docker* term is used for running commands. 

3. Build a Docker image. Provide a name for your image so you can refer to it later. To build an image, use the build command of docker.
Note that the Dockerfile takes into account the mandatory dependendies for you.

Please note that for the running commands below, the script takes into account only the MANDATORY parameters. It does not include the OPTIONAL parameters. Please read above the section of PARAMETERS OF PROFUNGIS to see below what we refer to. Additionally, for this example, we provide forward and reverse primers that are not in the primer.data list. This will show how to update the primer.data list by including more primer sequence references. 

```shell
docker build -t image001-startPROFUNGIS .  
```
where image001-startPROFUNGIS is the name of your image

4. Run the container by using the image you created in step 3. 

```shell
docker run image001-startPROFUNGIS python startPROFUNGIS.py -f ExampleF -r ExampleR -p illumina -m multirun_acc.txt
```

the PROFUNGIS Dockerfile specifies that this is a python dependent script, and the python command is required before listing the mandatory arguments.  

### OUTPUTS

The output directory contains several folders with intermediate products.
The present folders are:

1. filtered
2. merged
3. qual_filter
4. dereplicated
5. ZOTUS
6. FINAL
7. log

Placed in the order that they are created sequentially during the pipeline.
- The **"filtered"** folder contains the reads after primer filtering.
- The **"merged"** folder contains the merged reads. When the pipeline decided not to merge (or a pyrosequencing platform) is selected, the reads file in this folder is identical to that in the "filtered" folder. 
- The **"qual_filter"** folder contains the EE report and the reads that are filtered after this EE has been established.
- The **"dereplicated"** folder contains the reads after dereplication.
- The "ZOTUS" folder contains the final results of the pipeline: the ZOTU fasta and table files.
- The "log" directory contains the error logs for each of the previous mentioned steps.

**Subfolders**
*important note* as this will be important for the sequential pipelines to use.
Within the ZOTUS folder, there are two subdirectories. 
- In the main **"ZOTUS"** subdirectory, the initially generated ZOTUS
and ZOTU table can be found. 
- In the **"abundant"** folder, the ZOTUS are stored after the abundance filter. 
- In the **"FINAL"** folder, the final results of the pipeline are stored: the fasta file containing all fungal ITS ZOTUS and a txt file containing the table with read counts per ZOTU.





